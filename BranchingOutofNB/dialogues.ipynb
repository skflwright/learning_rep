{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = \"data.csv\"\n",
    "output_file = \"data.yaml\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('FDA_dialogue.csv')\n",
    "\n",
    "# Convert the DataFrame to a dictionary\n",
    "data_dict = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Write the dictionary to a YAML file\n",
    "with open(output_file, \"w\") as f:\n",
    "    yaml.dump(data_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Define the path to the text file\n",
    "text_file = \"Quora_duplicate_questions.csv.txt\"\n",
    "\n",
    "# Read in the text file\n",
    "with open(text_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Split the lines into questions and answers\n",
    "questions = []\n",
    "answers = []\n",
    "for line in lines:\n",
    "    # Split the line at the first colon to separate the question and answer\n",
    "    parts = line.strip().split(\":\", maxsplit=1)\n",
    "    if len(parts) == 2:\n",
    "        questions.append(parts[0].strip())\n",
    "        answers.append(parts[1].strip())\n",
    "\n",
    "# Combine the questions and answers into a list of dictionaries\n",
    "results = []\n",
    "for i in range(len(questions)):\n",
    "    result = {\"question\": questions[i], \"answer\": answers[i]}\n",
    "    results.append(result)\n",
    "\n",
    "# Define the path to the output file\n",
    "output_file = text_file.replace(\".txt\", \".yaml\")\n",
    "\n",
    "# Write the list of dictionaries to a YAML file\n",
    "with open(output_file, \"w\") as f:\n",
    "    yaml.dump(results, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a first crack at openai app... need to return to this later.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/skfl/learning/team-aajk/resources/dialogues/dialogues.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/skfl/learning/team-aajk/resources/dialogues/dialogues.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopenai\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/skfl/learning/team-aajk/resources/dialogues/dialogues.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/skfl/learning/team-aajk/resources/dialogues/dialogues.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Authenticate with OpenAI API\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import openai\n",
    "import yaml\n",
    "\n",
    "# Authenticate with OpenAI API\n",
    "openai.api_key = 'sk-D\"nObD5uEZGPuY40KfzSUT3BlbkFJx65Kht02EMdyYkNrM31W'\n",
    "\n",
    "# Define the path to the YAML file\n",
    "yaml_file = \"data.yaml\"\n",
    "\n",
    "# Load the YAML file into a Python object\n",
    "with open(yaml_file, \"r\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "# Create a list of prompts based on the questions in the YAML file\n",
    "prompts = [f\"Q: {item['question']}\\nA:\" for item in data]\n",
    "\n",
    "# Generate 100 questions and answers based on the prompts using the OpenAI GPT-3 API\n",
    "responses = []\n",
    "for prompt in prompts:\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    answer = response.choices[0].text.strip()\n",
    "    responses.append(answer)\n",
    "\n",
    "# Combine the original questions with the generated answers into a list of dictionaries\n",
    "results = []\n",
    "for i, item in enumerate(data):\n",
    "    result = {\n",
    "        \"question\": item[\"question\"],\n",
    "        \"answer\": responses[i]\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Write the list of dictionaries to a YAML file\n",
    "output_file = \"output.yaml\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    yaml.dump(results, f)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \"sk-D\"nObD5uEZGPuY40KfzSUT3BlbkFJx65Kht02EMdyYkNrM31W\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5d6e23cc21c3c22d5d038dfc2dc514a112c246cb6af6beae11f4484b62ad85b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
